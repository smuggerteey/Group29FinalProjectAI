{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"xkkfm-O5iS9J","executionInfo":{"status":"ok","timestamp":1701634381771,"user_tz":0,"elapsed":5709,"user":{"displayName":"Tinotenda Chagaka","userId":"03536502257059395116"}}},"outputs":[],"source":["# Import Dependencies\n","import csv\n","import pandas as pd\n","import numpy as np\n","from collections import defaultdict\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import keras\n","from keras.models import Sequential\n","from keras.applications.vgg16 import VGG16\n","from keras.layers import Dense, InputLayer, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n","from keras.preprocessing import image\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from keras.models import Model\n","from keras.layers import Input, Dense\n","from keras.optimizers import Adam\n","from sklearn.metrics import accuracy_score, roc_auc_score\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\n","from keras import regularizers"]},{"cell_type":"code","source":["# Mounting Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"vwLKQV_4ib1H"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HpWaoYxziS9K"},"outputs":[],"source":["# Read Raw Dataset\n","df = pd.read_excel('/content/drive/My Drive/AI_MedProject/raw_data.xlsx')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bqCLuw5yiS9K"},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZLlHv_wiS9L"},"outputs":[],"source":["# Fill all NaN with the values above\n","data = df.fillna(method='ffill')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aIxTOfdziS9L"},"outputs":[],"source":["data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93bgBJ9giS9L"},"outputs":[],"source":["# Process Disease and Symptom Names\n","def process_data(data):\n","    data_list = []\n","    data_name = data.replace('^','_').split('_')\n","    n = 1\n","    for names in data_name:\n","        if (n % 2 == 0):\n","            data_list.append(names)\n","        n += 1\n","    return data_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P03CRjdsiS9M"},"outputs":[],"source":["# Data Cleanup\n","disease_list = []\n","disease_symptom_dict = defaultdict(list)\n","disease_symptom_count = {}\n","count = 0\n","\n","for idx, row in data.iterrows():\n","\n","    # Get the Disease Names\n","    if (row['Disease'] !=\"\\xc2\\xa0\") and (row['Disease'] != \"\"):\n","        disease = row['Disease']\n","        disease_list = process_data(data=disease)\n","        count = row['Count of Disease Occurrence']\n","\n","    # Get the Symptoms Corresponding to Diseases\n","    if (row['Symptom'] !=\"\\xc2\\xa0\") and (row['Symptom'] != \"\"):\n","        symptom = row['Symptom']\n","        symptom_list = process_data(data=symptom)\n","        for d in disease_list:\n","            for s in symptom_list:\n","                disease_symptom_dict[d].append(s)\n","            disease_symptom_count[d] = count"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"DpkIOLtZiS9M"},"outputs":[],"source":["# See that the data is Processed Correctly\n","disease_symptom_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"OzR-qImviS9M"},"outputs":[],"source":["# Count of Disease Occurence w.r.t each Disease\n","disease_symptom_count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LXYQt5vMiS9N"},"outputs":[],"source":["# Save cleaned data as CSV\n","f = open('/content/drive/My Drive/AI_MedProject/cleaned_data.csv', 'w')\n","\n","with f:\n","    writer = csv.writer(f)\n","    for key, val in disease_symptom_dict.items():\n","        for i in range(len(val)):\n","            writer.writerow([key, val[i], disease_symptom_count[key]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EBmlLYwwiS9N"},"outputs":[],"source":["# Read Cleaned Data as DF\n","df = pd.read_csv('/content/drive/My Drive/AI_MedProject/cleaned_data.csv')\n","df.columns = ['disease', 'symptom', 'occurence_count']\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5rTb3BBiS9N"},"outputs":[],"source":["# Remove any rows with empty values\n","df.replace(float('nan'), np.nan, inplace=True)\n","df.dropna(inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IgBwGAWWiS9N"},"outputs":[],"source":["from sklearn import preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_sohaBKQiS9O"},"outputs":[],"source":["n_unique = len(df['symptom'].unique())\n","n_unique"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hsw6RDEoiS9O"},"outputs":[],"source":["df.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qIEpM8hCiS9O"},"outputs":[],"source":["# Encode the Labels\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","\n","label_encoder = LabelEncoder()\n","integer_encoded = label_encoder.fit_transform(df['symptom'])\n","print(integer_encoded)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"-4mHj4sEiS9O"},"outputs":[],"source":["# One Hot Encode the Labels\n","onehot_encoder = OneHotEncoder(sparse=False)\n","integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","print(onehot_encoded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hzRscpPKiS9P"},"outputs":[],"source":["onehot_encoded[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6So2tqPOiS9P"},"outputs":[],"source":["len(onehot_encoded[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-tUAhfkgiS9P"},"outputs":[],"source":["cols = np.asarray(df['symptom'].unique())\n","cols"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5kg89FH4iS9P"},"outputs":[],"source":["# Create a new dataframe to save OHE labels\n","df_ohe = pd.DataFrame(columns = cols)\n","df_ohe.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1U49_XsCiS9P"},"outputs":[],"source":["for i in range(len(onehot_encoded)):\n","    df_ohe.loc[i] = onehot_encoded[i]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5gcHbjPiS9P"},"outputs":[],"source":["df_ohe.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9PR_a4-qiS9Q"},"outputs":[],"source":["len(df_ohe)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYoi8vYJiS9Q"},"outputs":[],"source":["# Disease Dataframe\n","df_disease = df['disease']\n","df_disease.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGwmF5M5iS9Q"},"outputs":[],"source":["# Concatenate OHE Labels with the Disease Column\n","df_concat = pd.concat([df_disease,df_ohe], axis=1)\n","df_concat.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iHl3f6ILiS9Q"},"outputs":[],"source":["df_concat.drop_duplicates(keep='first',inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lAhxNHyFiS9Q"},"outputs":[],"source":["df_concat.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U1vWDBBxiS9Q"},"outputs":[],"source":["len(df_concat)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hX3me8OhiS9R"},"outputs":[],"source":["cols = df_concat.columns\n","cols"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-nU-tqRKiS9R"},"outputs":[],"source":["cols = cols[1:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M-SyPqSDiS9R"},"outputs":[],"source":["# Since, every disease has multiple symptoms, combine all symptoms per disease per row\n","df_concat = df_concat.groupby('disease').sum()\n","df_concat = df_concat.reset_index()\n","df_concat[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ufjGCunriS9R"},"outputs":[],"source":["len(df_concat)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fXrO_hgLiS9R"},"outputs":[],"source":["df_concat.to_csv(\"/content/drive/My Drive/AI_MedProject/training_dataset.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VySSrvRAiS9R"},"outputs":[],"source":["# One Hot Encoded Features\n","X = df_concat[cols]\n","\n","# Labels\n","y = df_concat['disease']"]},{"cell_type":"markdown","metadata":{"id":"F9ow4MhDiS9S"},"source":["## Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UauWEVLtiS9S"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn import tree\n","from sklearn.tree import DecisionTreeClassifier, export_graphviz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NogP6oFaiS9S"},"outputs":[],"source":["# Train Test Split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"]},{"cell_type":"code","source":["# Standardize the features\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)"],"metadata":{"id":"_tfP9i4DoQw7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Initialize the label encoder\n","label_encoder = LabelEncoder()\n","\n","# Encode the target variable\n","y_train_encoded = label_encoder.fit_transform(y_train)"],"metadata":{"id":"bmvDMvpMo_Ub"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Example input sequences\n","sequences = [[1, 2, 3], [4, 5], [6, 7, 8, 9]]\n","\n","# Pad sequences to a maximum length of 200\n","padded_sequences = pad_sequences(sequences, maxlen=200)\n","\n","print(padded_sequences)"],"metadata":{"id":"o_Z7h0xRtGpf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","vocab_size = 10000  # Replace with the actual vocabulary size\n","embedding_dim = 100  # Replace with the desired embedding dimension\n","max_len = 200  # Replace with the maximum sequence length\n","num_classes = 10  # Replace with the actual number of classes in your problem\n","epochs = 200\n","\n","# Example input sequences\n","your_input_sequences = [[1, 2, 3], [4, 5], [6, 7, 8, 9]]\n","\n","# Pad sequences to a maximum length of 200\n","padded_sequences = pad_sequences(your_input_sequences, maxlen=max_len)\n","\n","# Example training labels\n","your_training_labels = [0, 1, 0]  # Replace with your actual training labels\n","\n","# Convert training labels to NumPy array\n","training_labels = np.array(your_training_labels)\n","\n","model = Sequential()\n","model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n","model.add(LSTM(110, return_sequences=True))\n","model.add(LSTM(110))\n","model.add(Dense(208, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(optimizer=Adam(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","\n","# Train the model on the training set with validation split\n","history = model.fit(padded_sequences, training_labels, epochs=epochs, validation_split=0.2)\n","\n","# Calculate validation accuracy manually\n","validation_accuracy = model.evaluate(padded_sequences, training_labels)[1]\n","\n","# Plot the training and validation loss\n","plt.plot(range(1, epochs + 1), history.history['loss'], label='Training Loss')\n","plt.plot(range(1, epochs + 1), history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()\n","\n","# Plot the training and validation accuracy\n","plt.plot(range(1, epochs + 1), history.history['accuracy'], label='Training Accuracy')\n","plt.plot(range(1, epochs + 1), history.history['val_accuracy'], label='Validation Accuracy')\n","plt.axhline(y=validation_accuracy, color='r', linestyle='--', label='Final Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"BExqnRPevlxb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"06w8eML8iS9Y"},"outputs":[],"source":["len(X_test), len(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nu_dmvjEiS9Y"},"outputs":[],"source":["dt = DecisionTreeClassifier()\n","clf_dt=dt.fit(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1kOSAziciS9Y"},"outputs":[],"source":["clf_dt.score(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6mhza1ftiS9Z"},"outputs":[],"source":["disease_pred = clf_dt.predict(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PB6HyL9OiS9Z"},"outputs":[],"source":["disease_real = y.values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j98pSkI0iS9Z"},"outputs":[],"source":["for i in range(0, len(disease_real)):\n","    if disease_pred[i]!=disease_real[i]:\n","        print ('Pred: {0}\\nActual: {1}\\n'.format(disease_pred[i], disease_real[i]))"]},{"cell_type":"code","source":["# Save the trained model\n","model.save(\"/content/drive/My Drive/AI_MedProject/chat_model\")"],"metadata":{"id":"MDg6Xz3kylxg"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}